{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LjrtE6jITXcT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import List, Dict\n",
        "import scipy.integrate\n",
        "from scipy.integrate import solve_ivp\n",
        "import autograd.numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import autograd.numpy as np\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 34869261 #m\n",
        "mu = 3.9860064E+14 #ùëö3/ùë†2\n",
        "R = 6378139 #m\n",
        "\n",
        "# Orbit period is calculated through Kepler's Third Law:\n",
        "T = np.sqrt(a**3*(4*np.pi**2/mu)) #s\n",
        "time_step = T/400"
      ],
      "metadata": {
        "id": "jp_SIK34VhAd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def ABM(model, x0, sf, s0,aug=0):\n",
        "    # Constants\n",
        "    a = 34869261  # m\n",
        "    mu = 3.9860064E+14  # m^3/s^2\n",
        "\n",
        "    # Orbit period calculated through Kepler's Third Law\n",
        "    T = np.sqrt(a**3 * (4 * np.pi**2 / mu))\n",
        "    ########## FIXXXX\n",
        "    ds = 1\n",
        "    #print(\"Step size (ds):\", ds)\n",
        "\n",
        "    # Calculate number of steps based on the given time interval and step size\n",
        "    s = np.arange(s0, sf, ds)\n",
        "    ns = len(s)  # Get the exact number of elements in s\n",
        "\n",
        "    # Ensure x0 is a torch tensor with the correct shape\n",
        "    if not isinstance(x0, torch.Tensor):\n",
        "        x0 = torch.tensor(x0, dtype=torch.float32)\n",
        "    if x0.dim() == 1:\n",
        "        x0 = x0.unsqueeze(0)  # Ensures x0 is [1, 6] if it's provided as [6]\n",
        "\n",
        "    # Initialize the tensor to store the simulation results\n",
        "    x = torch.zeros((ns, x0.size(1)), dtype=x0.dtype, device=x0.device)\n",
        "    # print(\"x0\",x0)\n",
        "    # Set initial state\n",
        "    x[0, :] = x0.squeeze()  # Make sure x0 is squeezed to [6]\n",
        "    f = model.func\n",
        "    theta = model.theta\n",
        "    # First initialize with an RK4 step for stability in starting the integration\n",
        "    for k in range(3):\n",
        "        if k + 1 < ns:\n",
        "            k1 = ds * f(s[k], x[k, :],theta,aug)\n",
        "            k2 = ds * f(s[k] + ds/2, x[k, :] + k1/2,theta,aug)\n",
        "            k3 = ds * f(s[k] + ds/2, x[k, :] + k2/2,theta,aug)\n",
        "            k4 = ds * f(s[k] + ds, x[k, :] + k3,theta,aug)\n",
        "            dx = (k1 + 2*k2 + 2*k3 + k4) / 6\n",
        "            x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "    # ABM integration\n",
        "    for k in range(3, ns - 1):\n",
        "        if k - 3 >= 0:  # Make sure indices don't go out of bounds\n",
        "            f_m3 = f(s[k-3], x[k-3, :],theta,aug)\n",
        "            f_m2 = f(s[k-2], x[k-2, :],theta,aug)\n",
        "            f_m1 = f(s[k-1], x[k-1, :],theta,aug)\n",
        "            f_0 = f(s[k], x[k, :],theta,aug)\n",
        "\n",
        "            # Predictor\n",
        "            dx = (ds/24) * (55 * f_0 - 59 * f_m1 + 37 * f_m2 - 9 * f_m3)\n",
        "            x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "            # Evaluate at the predicted next step (ensure not at the last step)\n",
        "            if k + 1 < ns - 1:\n",
        "                f_p1 = f(s[k + 1], x[k + 1, :],theta,aug)\n",
        "                # Corrector\n",
        "                dx = (ds/24) * (9 * f_p1 + 19 * f_0 - 5 * f_m1 + f_m2)\n",
        "                x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "    # Return the results\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "CJCcHDpeTeBH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ABM_aug(f, x0, sf, s0,theta,aug=1):\n",
        "    # Constants\n",
        "    a = 34869261  # m\n",
        "    mu = 3.9860064E+14  # m^3/s^2\n",
        "    aug = 0\n",
        "    # Orbit period calculated through Kepler's Third Law\n",
        "    T = np.sqrt(a**3 * (4 * np.pi**2 / mu))\n",
        "    ########## FIXXXX\n",
        "    ds = 1\n",
        "    #print(\"Step size (ds):\", ds)\n",
        "\n",
        "    # Calculate number of steps based on the given time interval and step size\n",
        "    s = np.arange(s0, sf, ds)\n",
        "    ns = len(s)  # Get the exact number of elements in s\n",
        "\n",
        "    # Ensure x0 is a torch tensor with the correct shape\n",
        "    if not isinstance(x0, torch.Tensor):\n",
        "        x0 = torch.tensor(x0, dtype=torch.float32)\n",
        "    if x0.dim() == 1:\n",
        "        x0 = x0.unsqueeze(0)  # Ensures x0 is [1, 6] if it's provided as [6]\n",
        "\n",
        "    # Initialize the tensor to store the simulation results\n",
        "    x = torch.zeros((ns, x0.size(1)), dtype=x0.dtype, device=x0.device)\n",
        "    # print(\"x0\",x0)\n",
        "    # Set initial state\n",
        "    x[0, :] = x0.squeeze()  # Make sure x0 is squeezed to [6]\n",
        "    # First initialize with an RK4 step for stability in starting the integration\n",
        "    for k in range(3):\n",
        "        if k + 1 < ns:\n",
        "            k1 = ds * f(s[k], x[k, :],theta,aug)\n",
        "            k2 = ds * f(s[k] + ds/2, x[k, :] + k1/2,theta,aug)\n",
        "            k3 = ds * f(s[k] + ds/2, x[k, :] + k2/2,theta,aug)\n",
        "            k4 = ds * f(s[k] + ds, x[k, :] + k3,theta,aug)\n",
        "            dx = (k1 + 2*k2 + 2*k3 + k4) / 6\n",
        "            x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "    # ABM integration\n",
        "    for k in range(3, ns - 1):\n",
        "        if k - 3 >= 0:  # Make sure indices don't go out of bounds\n",
        "            f_m3 = f(s[k-3], x[k-3, :],theta,aug)\n",
        "            f_m2 = f(s[k-2], x[k-2, :],theta,aug)\n",
        "            f_m1 = f(s[k-1], x[k-1, :],theta,aug)\n",
        "            f_0 = f(s[k], x[k, :],theta,aug)\n",
        "\n",
        "            # Predictor\n",
        "            dx = (ds/24) * (55 * f_0 - 59 * f_m1 + 37 * f_m2 - 9 * f_m3)\n",
        "            x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "            # Evaluate at the predicted next step (ensure not at the last step)\n",
        "            if k + 1 < ns - 1:\n",
        "                f_p1 = f(s[k + 1], x[k + 1, :],theta,aug)\n",
        "                # Corrector\n",
        "                dx = (ds/24) * (9 * f_p1 + 19 * f_0 - 5 * f_m1 + f_m2)\n",
        "                x[k + 1, :] = x[k, :] + dx\n",
        "\n",
        "    # Return the results\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "TaCEL3lUUF9j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def X_ddot(t, X,theta,aug):\n",
        "    mu = 4 #ùëö3/ùë†2\n",
        "    '''\n",
        "    Returns the derivative of the state vector X\n",
        "    ----------\n",
        "    Arguments:\n",
        "        t {float} -- time, in seconds\n",
        "        X {np.array} -- state vector=(x, y, z, vx, vy, vz)\n",
        "    ----------\n",
        "    Returns:\n",
        "        (6,1) np.array -- (xdot, ydot, zdot, vxdot, vydot, vzdot)\n",
        "    '''\n",
        "    x_dot = X[3:]\n",
        "    v_dot = -mu*X[:3]/np.linalg.norm(X.detach().numpy())**3 # simply the acceleration\n",
        "\n",
        "    X_dot_dot = np.concatenate((x_dot.detach().numpy(), v_dot.detach().numpy()), axis=None)\n",
        "\n",
        "    X_dot_dot = torch.tensor(X_dot_dot, dtype=torch.float32, requires_grad=True)\n",
        "    if not aug:\n",
        "      X_dot_dot = theta*X_dot_dot\n",
        "    return X_dot_dot"
      ],
      "metadata": {
        "id": "hofyyMD_TsOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def X_ddottrue(t, X,theta,aug):\n",
        "    mu = 2 #ùëö3/ùë†2\n",
        "    '''\n",
        "    Returns the derivative of the state vector X\n",
        "    ----------\n",
        "    Arguments:\n",
        "        t {float} -- time, in seconds\n",
        "        X {np.array} -- state vector=(x, y, z, vx, vy, vz)\n",
        "    ----------\n",
        "    Returns:\n",
        "        (6,1) np.array -- (xdot, ydot, zdot, vxdot, vydot, vzdot)\n",
        "    '''\n",
        "    x_dot = X[3:]\n",
        "    v_dot = -mu*X[:3]/np.linalg.norm(X.detach().numpy())**3 # simply the acceleration\n",
        "\n",
        "    X_dot_dot = np.concatenate((x_dot.detach().numpy(), v_dot.detach().numpy()), axis=None)\n",
        "    X_dot_dot = torch.tensor(X_dot_dot, dtype=torch.float32, requires_grad=True)\n",
        "    return X_dot_dot"
      ],
      "metadata": {
        "id": "774TqslI5Tnp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to create a custom forward and backwards pass\n",
        "# use torch.autograd.Function for this purpose\n",
        "class ODEForwardBackward(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, z0, theta ,t0 , t1,model):\n",
        "        # Ensure initial state and time vector are properly formatted\n",
        "        z0 = z0.squeeze()  # Correct shape if necessary\n",
        "        z = torch.zeros((z0.size(0)), dtype=z0.dtype, device=z0.device)\n",
        "\n",
        "        # Simulate the dynamics over the given time frame\n",
        "        z = ABM(model, z0, t1, t0,aug=0)\n",
        "        # print(\"forward z\",z[-1])\n",
        "        # Save for backward pass\n",
        "        ctx.save_for_backward(z[-1], t0,t1, theta)\n",
        "        ctx.model = model\n",
        "\n",
        "        # Return the final state\n",
        "        return z[-1]\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    # pytorch AUTOMATICALLY gives us the loss gradient over the entire function.\n",
        "    # therefore, from that gradient, we must return dldz0, dldt, and dldp\n",
        "    # this is outlined in the appendix\n",
        "    def backward(ctx, grad_zt1):\n",
        "        z,t0,t1,theta = ctx.saved_tensors\n",
        "        zt1 = z\n",
        "        #print(\"BACK\")\n",
        "        #print(\"zt1\",zt1)\n",
        "        #print(\"t0\",t0)\n",
        "        #print(\"t1\",t1)\n",
        "        model = ctx.model\n",
        "        #print(\"num parma\",len(theta))\n",
        "        #print(\"theta\",theta)\n",
        "\n",
        "        # Reconstruct augmented state at final time\n",
        "        grad_t1 = grad_zt1 * model.func(t1,zt1,theta,aug=0)[-1]  # Assuming scalar t\n",
        "\n",
        "        # print(\"BACK2\")\n",
        "        # print(grad_t1)\n",
        "        aug_state0 = torch.cat([zt1, -grad_zt1, torch.zeros_like(theta).flatten(), -grad_t1])\n",
        "        # Reverse time ODE solve (backpropagate from t1 to t0) THIS IS WRONG\n",
        "        #audited_dynamics = Augmented_dynamics(model=model)\n",
        "        #print(\"aug_state0\",aug_state0)\n",
        "        aug_state_t0 = ABM_aug(model.func,aug_state0, t1, t0,model.adtheta,0)\n",
        "\n",
        "        # Extract gradients w.r.t. initial state, parameters, and initial and final times\n",
        "        #print(\"aug_0\",aug_state_t0)\n",
        "        # print(\"HEEE\",aug_state_t0.size)\n",
        "        #print(\"aug_0\",aug_state_t0[-1])\n",
        "        aug_state_t0 = aug_state_t0[-1]\n",
        "\n",
        "        #print(\"z0_aug\",aug_state_t0[0:6] )\n",
        "        #print(\"grad_z0\",aug_state_t0[6:12])\n",
        "        grad_z0 = aug_state_t0[6:12].unsqueeze(0)\n",
        "        #print(\"grad_theta\",aug_state_t0[12:12+len(theta)])\n",
        "        grad_theta = aug_state_t0[12:12+len(theta)].unsqueeze(0)\n",
        "        #print(\"grad_t0/grad_t1\",aug_state_t0[12+len(theta):12+len(theta)+6],grad_t1)\n",
        "        grad_t0 = aug_state_t0[12+len(theta):].unsqueeze(0)\n",
        "\n",
        "        # Return gradients\n",
        "        return grad_z0, grad_theta, grad_t0, grad_t1,None\n"
      ],
      "metadata": {
        "id": "Nt7RYVV8UmvI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralODE(nn.Module):\n",
        "  def __init__(self,func):\n",
        "    super().__init__()\n",
        "    self.func = func\n",
        "    self.adtheta = nn.Parameter(torch.ones(6*4, requires_grad=True))\n",
        "    self.theta = nn.Parameter(torch.ones(6, requires_grad=True))\n",
        "\n",
        "  def forward(self, z0, t0,t1):\n",
        "    # Pass the input through the function\n",
        "    return ODEForwardBackward.apply(z0, self.theta, t0, t1, self)"
      ],
      "metadata": {
        "id": "XDiRmSPgUg_h"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation\n",
        "\n",
        "model = NeuralODE(X_ddot)\n",
        "\n",
        "x = [[0,1,1,0,1,2]]\n",
        "x_tensor = torch.tensor(x, dtype=torch.float32)\n",
        "t = np.linspace(0, 10,num=25)\n",
        "t_tensor = torch.tensor(t, dtype=torch.float32)\n",
        "y=ABM_aug(X_ddottrue,x_tensor,t_tensor[1],t_tensor[0],0)\n",
        "y_tensor = y.unsqueeze(0)\n",
        "\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "# training\n",
        "\n",
        "\n",
        "model.train()\n",
        "epochs = 20\n",
        "# for now, do batch size of 1, for simpler adjustments in ODE\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "  for x_1, y_1 in dataloader:\n",
        "    x_1 = torch.autograd.Variable(x_1, requires_grad=True)\n",
        "    y_1 = torch.autograd.Variable(y_1, requires_grad=True)\n",
        "    p = torch.randn(6, requires_grad=True)\n",
        "    y_pred = model(x_1, t_tensor[0] , t_tensor[-1])\n",
        "    #print(\"y_pred\",y_pred)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(y_pred.unsqueeze(0), y_1)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  average_loss = total_loss / len(x)\n",
        "  print (\"Epoch:\", epoch, \"Average Loss:\", average_loss)\n",
        "\n",
        "\n",
        "Xtrue = [[0,1,1,0,1,2]]\n",
        "Xtrue = torch.tensor(Xtrue, dtype=torch.float32)\n",
        "X_i = Xtrue\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  y_pred = model(x_tensor, t_tensor[0] , t_tensor[-1])\n",
        "  print(\"y_pred\",y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ZfhGxOUwev",
        "outputId": "296c87ad-0244-4f26-e6fb-43817e25d7d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1, 1, 6])) that is different to the input size (torch.Size([1, 6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Average Loss: 38.491519927978516\n",
            "Epoch: 1 Average Loss: 45.6891975402832\n",
            "Epoch: 2 Average Loss: 41.60418701171875\n",
            "Epoch: 3 Average Loss: 35.15445327758789\n",
            "Epoch: 4 Average Loss: 29.105987548828125\n",
            "Epoch: 5 Average Loss: 26.332839965820312\n",
            "Epoch: 6 Average Loss: 26.16634178161621\n",
            "Epoch: 7 Average Loss: 27.006698608398438\n",
            "Epoch: 8 Average Loss: 27.4632511138916\n",
            "Epoch: 9 Average Loss: 26.30755043029785\n",
            "Epoch: 10 Average Loss: 23.641557693481445\n",
            "Epoch: 11 Average Loss: 20.560087203979492\n",
            "Epoch: 12 Average Loss: 18.66804313659668\n",
            "Epoch: 13 Average Loss: 18.411569595336914\n",
            "Epoch: 14 Average Loss: 19.066787719726562\n",
            "Epoch: 15 Average Loss: 19.55122184753418\n",
            "Epoch: 16 Average Loss: 18.73280143737793\n",
            "Epoch: 17 Average Loss: 17.0529842376709\n",
            "Epoch: 18 Average Loss: 16.174327850341797\n",
            "Epoch: 19 Average Loss: 16.578828811645508\n",
            "y_pred tensor([ 0.0000,  1.8844, 10.9756,  0.0000, -0.2484,  0.2498])\n"
          ]
        }
      ]
    }
  ]
}